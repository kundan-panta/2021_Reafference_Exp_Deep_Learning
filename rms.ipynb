{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.7 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all files to extract the data from (collected at multiple locations)\n",
    "file_names = ['12','14','16','18','20','22','24','26','28','30']\n",
    "\n",
    "# choose trajectory name for which to process data\n",
    "trajectory_name = '30deg'\n",
    "\n",
    "# I might have to use a for loop (for ease) at each location, since the length of data at each location might differ by a small number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "t = np.around(np.loadtxt('t.csv', delimiter=',', unpack=True), decimals=3)  # round to ms\n",
    "ft_meas = np.loadtxt('ft_meas.csv', delimiter=',', unpack=True)\n",
    "ang_meas = np.loadtxt('ang_meas.csv', delimiter=',', unpack=True)\n",
    "cpg_param = np.loadtxt('cpg_param.csv', delimiter=',', unpack=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of unused data points:\n[249 249 249]\n"
     ]
    }
   ],
   "source": [
    "N = len(cpg_param[1])  # number of data points\n",
    "\n",
    "####################### WILL BE OBSOLETE ########################\n",
    "## find points where new cpg parameters are used\n",
    "cpg_param_change = cpg_param[:, 0:(N-1)] - cpg_param[:, 1:N]\n",
    "cpg_param_change_idx = np.nonzero(cpg_param_change)[1] + 1\n",
    "# [1] means take the 2nd input of the nonzero() fcn, which gives where nonzero input by column\n",
    "# +1 needed so idx is for start of new param set, rather than end of old param set\n",
    "\n",
    "# test = cpg_param[:, cpg_param_change_idx[1] - 1]  # checking if the cpg params really change at the index\n",
    "\n",
    "cpg_param_change_idx = np.insert(cpg_param_change_idx, 0, 0)  # including the first one\n",
    "cpg_param_change_idx = cpg_param_change_idx.astype(int)\n",
    "\n",
    "N_param = len(cpg_param_change_idx)  # number of param sets\n",
    "#################################################################\n",
    "\n",
    "\n",
    "## find points where a new stroke cycle is started\n",
    "t_s = round(t[1] - t[0], 3)  # sample time\n",
    "f_param = cpg_param[-1, cpg_param_change_idx]  # store frequencies of each param set\n",
    "t_cycle_param = np.around(1 / f_param, decimals=3)  # stroke cycle time\n",
    "\n",
    "# calculate number of cycles\n",
    "t_param = np.zeros(N_param)  # period of time over which data has been collected for each param set\n",
    "for i in range(N_param):\n",
    "    if i < N_param-1:\n",
    "        t_param[i] = t[cpg_param_change_idx[i+1] - 1] - t[cpg_param_change_idx[i]]\n",
    "    else:\n",
    "        t_param[i] = t[-1] - t[cpg_param_change_idx[i]]\n",
    "t_param += t_s  # including first point\n",
    "t_param = np.around(t_param, decimals=3)\n",
    "\n",
    "N_cycles = (t_param / t_cycle_param).astype(int)  # total time of data collection / time for 1 stroke cycle\n",
    "if np.any(N_cycles != N_cycles[0]):\n",
    "    print('Different number of cycles for different parameter sets.')\n",
    "    raise\n",
    "N_cycles = N_cycles[0]\n",
    "\n",
    "# calculate number of data points per cycle\n",
    "N_per_cycle = (t_cycle_param / t_s).astype(int)\n",
    "\n",
    "# print number of unused data points\n",
    "print('Number of unused data points:')\n",
    "print((t_param / t_s).astype(int) - N_per_cycle * N_cycles)  # total # of data points - # of data points used"
   ]
  },
  {
   "source": [
    "How should I organize this data? What are my goals?\n",
    "I'm trying to figure out the RMS for every stroke cycle. Additionally, I want to know which stroke cycle belongs to which parameter set.\n",
    "After taking the RMS, I will have one value for each cycle, categorized by the parameter set used.\n",
    "Finally, for each parameter set, I will average the RMS values for all cycles in that parameter set.\n",
    "Which of these intermediate values are important to see for myself?\n",
    "I don't need to see the FT data for each stroke cycle. But I would like to see the RMS values for each stroke cycle.\n",
    "I would also want to separate the array of RMS values by set so I know which array of RMS values is for each parameter set.\n",
    "I also want to see the averaged RMS value for each parameter set.\n",
    "Actually, I'll have a RMS value for each of the 6 FT.\n",
    "Later, I'll also have to do this for every distance from the wall."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# 3d matrix, 1st dim is a param set, 2nd dim is stroke cycle, 3rd dim are the 6 FT\n",
    "# need to have same number of cycles for each param set\n",
    "# at the same time, also do the same for the magnitude of FT instead of the 3 directions separately\n",
    "rms_all = np.zeros((N_param, N_cycles, 6))\n",
    "rms_norm_all = np.zeros((N_param, N_cycles, 2))\n",
    "\n",
    "## calculate RMS values for each FT, for each stroke cycle, for each param set\n",
    "for i in range(N_param):\n",
    "    for j in range(N_cycles):\n",
    "        # get ft_meas_cycle\n",
    "        ft_meas_cycle = ft_meas[:, (cpg_param_change_idx[i] + j*N_per_cycle[i]):(cpg_param_change_idx[i] + (j+1)*N_per_cycle[i])]\n",
    "        # take norm of F and T separately\n",
    "        f_meas_norm_cycle = np.linalg.norm(ft_meas_cycle[0:3,:],axis=0)\n",
    "        T_meas_norm_cycle = np.linalg.norm(ft_meas_cycle[3:6,:],axis=0)\n",
    "\n",
    "        # rms\n",
    "        rms_all[i, j, :] = np.sqrt(1/N_per_cycle[i] * np.sum(ft_meas_cycle**2, axis=1))\n",
    "        rms_norm_all[i, j, 0] = np.sqrt(1/N_per_cycle[i] * np.sum(f_meas_norm_cycle**2))\n",
    "        rms_norm_all[i, j, 1] = np.sqrt(1/N_per_cycle[i] * np.sum(T_meas_norm_cycle**2))\n",
    "\n",
    "# average the FT RMS for across all stroke cycles\n",
    "rms_avg = np.mean(rms_all, axis=1)\n",
    "rms_norm_avg = np.mean(rms_norm_all, axis=1)\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing for latex\n",
    "import array_to_latex as a2l\n",
    "\n",
    "a2l.to_clp(rms_avg.transpose(), frmt = '{:6.4f}', arraytype = 'tabular')\n",
    "# a2l.to_clp(rms_norm_avg.transpose(), frmt = '{:6.4f}', arraytype = 'tabular')\n"
   ]
  }
 ]
}